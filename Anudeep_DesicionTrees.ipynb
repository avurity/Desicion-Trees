{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "data_train = pd.read_csv('data/train.csv', dtype=int) # read train data\n",
    "data_test = pd.read_csv('data/test.csv', dtype=int) # read test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How many images are in the data set? What is the dimension of the feature vector and what are the features?\n",
    "\n",
    "Ans: There are 60000 images in training dataset and 10000 images in test dataset. But there are only 10 varities of images that are in label coloumn in this dataset. There are 784 pixcels which represents one image. The Xtrain features dimension is 60000 X 784. Where as X_test feature dimension is 10000 X 784.The features are Pixels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_labels(labels):\n",
    "    text_labels=['t-shirt','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (b) Before it is possible to design a classifer, it is necessary to divide the data into label and feature sets. This may be done with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_train.iloc[:,0:784].values\n",
    "y_train = data_train.iloc[:, 0].values\n",
    "X_test = data_test.iloc[:, 0:784].values\n",
    "y_test = data_test.iloc[:, 0].values\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label  9\n"
     ]
    }
   ],
   "source": [
    "X_train = data_train.drop('label', axis=1)\n",
    "y_train = data_train['label']\n",
    "X_test = data_test.drop('label', axis=1)\n",
    "y_test = data_test['label']\n",
    "plt.imshow(X_train.iloc[1,:].values.reshape([28,28])) \n",
    "plt.show()\n",
    "print('Label ',y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a) Design a deep decision tree classifer using the test data X_test and y_test. Begin by using the default values for all hyper parameters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_model = DecisionTreeClassifier()\n",
    "x=Tree_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b) Determine the accuracy of your model on the training data.\n",
    "Evaluate the training accuracy. the accuracy is one. This gives an idea that our model overfitted. Lets us evaluate in detail using confusion matrix for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "Tree_model_accuracy = (x.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',Tree_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy can be estimated by using confusion matirx.\n",
    "Ans: This confusion matrix looks perfect, since most images are on the main diagonal, which means that they were classified absolutely correct. That means there are overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6000    0    0    0    0    0    0    0    0    0]\n",
      " [   0 6000    0    0    0    0    0    0    0    0]\n",
      " [   0    0 6000    0    0    0    0    0    0    0]\n",
      " [   0    0    0 6000    0    0    0    0    0    0]\n",
      " [   0    0    0    0 6000    0    0    0    0    0]\n",
      " [   0    0    0    0    0 6000    0    0    0    0]\n",
      " [   0    0    0    0    0    0 6000    0    0    0]\n",
      " [   0    0    0    0    0    0    0 6000    0    0]\n",
      " [   0    0    0    0    0    0    0    0 6000    0]\n",
      " [   0    0    0    0    0    0    0    0    0 6000]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mx= confusion_matrix(Tree_model.predict(X_train),y_train)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "print(conf_mx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2(c) Cross Validation \n",
    "Does it appear that your decision tree is either underfitting or overfitting the data?Explain.\n",
    "\n",
    "ans: The decesion Tree is right now Overfitting. The mean accuracy tell that my model for this data has poor performance this is because we did not set any limit to the growth of the of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "all_accuracies = cross_val_score(estimator=x, X=X_train, y=y_train, cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78858333 0.79125    0.7925     0.7985     0.79008333]\n",
      "0.7921833333333334\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies)\n",
    "print(all_accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2(d) Repeat part (a) and remodel the classifier using growth limit.\n",
    "Minimum sample leaf = 5 and max depth of 12 was set. The accuracy was around 87%.After looking at the new training accuracy, we can say that the model is now not overfitting like before. Event though the model is not the best, we managed to remove the overfitting by limiting the growth of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.8759833333333333\n",
      "[0.81375    0.81025    0.81841667 0.81666667 0.81283333]\n",
      "0.8143833333333333\n"
     ]
    }
   ],
   "source": [
    "Tree_models = DecisionTreeClassifier(min_samples_leaf=5,max_depth=12).fit(X_train,y_train)\n",
    "Tree_models_accuracy = (Tree_models.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',Tree_models_accuracy)\n",
    "all_accuracies1 = cross_val_score(estimator=Tree_model, X=X_train, y=y_train, cv=5)\n",
    "\n",
    "print(all_accuracies1)\n",
    "print(all_accuracies1.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2(e) This is a Confusion matrix with Little variation in the image. \n",
    "This says that even though we have introduced the growth limiters we are still facing a problem in the performance.Instead of randomly selecting the values of the parameters, a better approach would be to use a procedure that automatically finds the best parameters for a particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5361   41   69  229   29    6  752    7   34   12]\n",
      " [   6 5750    6   27   12    1    5    0   10    1]\n",
      " [  67   16 4673   70  576    3  597    0   39    7]\n",
      " [ 127  137   46 5367  268   10  119    0   34    3]\n",
      " [  45   16  803  176 4781    1  591    0   52    2]\n",
      " [   7    7    5    4    4 5682    8   85   18   43]\n",
      " [ 365   25  371  113  311    7 3878    0   69    8]\n",
      " [   3    2    1    0    0  211    1 5756   20  318]\n",
      " [  18    5   24   11   19   30   46   15 5717   12]\n",
      " [   1    1    2    3    0   49    3  137    7 5594]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mx= confusion_matrix(Tree_model.predict(X_train),y_train)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "print(conf_mx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we look at the image we can notice that few diagonals are grey in color and also sqaures like (2,4),(4,2),(4,6),(2,6) and (0,6) are confused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(f) The Grid Search shows that Best criterian is entropy with max depth of 15 and mid sample leaf of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 20}\n",
      "0.8149666666666666\n"
     ]
    }
   ],
   "source": [
    "grid_param = { 'min_samples_leaf':[5, 10, 15, 20], 'max_depth':[5, 10, 15, 20], \n",
    "              'criterion': ['gini', 'entropy'] }\n",
    "gd_sr = GridSearchCV(estimator=Tree_model, param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "gd_sr.fit(X_train, y_train)\n",
    "best_parameters = gd_sr.best_params_\n",
    "print(best_parameters)\n",
    "best_result = gd_sr.best_score_\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3(a): Use AdaBoostClassifier to design a strong classifier using the training data (X_train,y_train) created in part (a). Use a decision stump as the base classifier, and set n_estimators=300.\n",
    "It is clear that the desicion stumps training accuracy is less than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(n_estimators=300)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3(b) Determine the accuracy of your model on the training data and estimate the expected error using cross-validation.\n",
    "ans= the cross validation error is around 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.4201\n",
      "[0.41875    0.43483333 0.47791667 0.41808333 0.39991667]\n"
     ]
    }
   ],
   "source": [
    "ada_clf_accuracy = (ada_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',ada_clf_accuracy)\n",
    "\n",
    "all_accuracies = cross_val_score(estimator=ada_clf, X=X_train, y=y_train, cv=5)\n",
    "print(all_accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(c) Use the grid search algorithm to determine the best number of estimators to use, and plot the validation error as a function of the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "                            \"n_estimators\": [50,100,200]}\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth = 1, class_weight = \"balanced\")\n",
    "\n",
    "ada_clf = AdaBoostClassifier(base_estimator = tree_model)\n",
    "\n",
    "# run grid search\n",
    "gd_sr_ada = GridSearchCV(ada_clf, param_grid=param_grid, scoring = 'accuracy',cv=5, n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
    "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
    "                                          base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                                                criterion='gini',\n",
    "                                                                                max_depth=1,\n",
    "                                                                                max_features=None,\n",
    "                                                                                max_leaf_nodes=None,\n",
    "                                                                                min_impurity_decrease=0.0,\n",
    "                                                                                min_impurity_split=None,\n",
    "                                                                                min_samples_leaf=1,\n",
    "                                                                                min_samples_split=2,\n",
    "                                                                                min_weight_fraction_leaf=0.0,\n",
    "                                                                                presort=False,\n",
    "                                                                                random_state=None,\n",
    "                                                                                splitter='best'),\n",
    "                                          learning_rate=1.0, n_estimators=50,\n",
    "                                          random_state=None),\n",
    "             iid='warn', n_jobs=-1,\n",
    "             param_grid={'base_estimator__criterion': ['gini', 'entropy'],\n",
    "                         'n_estimators': [50,100,200]},\n",
    "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
    "             scoring='accuracy', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr_ada.fit(X_train, y_train)\n",
    "best_parameters = gd_sr_ada.best_params_\n",
    "print(best_parameters)\n",
    "best_result = gd_sr_ada.best_score_\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The result after running the above code\n",
    "{'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best', 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(d)Analyze and comment on your results. How do your results change if you were to use a decision tree with a maximum depth of two instead of one as you have with a decision Stump classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.6051666666666666\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=200,\n",
    "algorithm=\"SAMME.R\")\n",
    "ada_clf.fit(X_train, y_train)\n",
    "ada_clf_accuracy = (ada_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',ada_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  4(a) Use RandomForestClassifier to design a strong classifier using the data (X_train,y_train) created in the boosting exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1, oob_score=True)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "grid_param = { 'min_samples_leaf':[5, 10, 15, 20], 'max_depth':[5, 10, 15, 20], \n",
    "              'criterion': ['gini', 'entropy'] }\n",
    "gd_sr = GridSearchCV(estimator= rnd_clf, param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "gd_sr.fit(X_train, y_train)\n",
    "best_parameters = gd_sr.best_params_\n",
    "print(best_parameters)\n",
    "best_result = gd_sr.best_score_\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'max_depth': 20, 'min_samples_leaf': 10}\n",
    "\n",
    "0.8735333333333334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score when number of trees is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.5678\n",
      "Training accuracy =  0.572\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1, oob_score=True)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",rnd_clf.oob_score_)\n",
    "rnd_clf_accuracy = (rnd_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',rnd_clf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score when number of tree is 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.6103\n",
      "Training accuracy =  0.62165\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=200, max_depth=2, n_jobs=-1, oob_score=True)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",rnd_clf.oob_score_)\n",
    "rnd_clf_accuracy = (rnd_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',rnd_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score when number of tree is 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.605\n",
      "Training accuracy =  0.6143833333333333\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=300, max_depth=2, n_jobs=-1, oob_score=True)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",rnd_clf.oob_score_)\n",
    "rnd_clf_accuracy = (rnd_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',rnd_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score when number of tree is 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.6116\n",
      "Training accuracy =  0.6205666666666667\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_depth=2, n_jobs=-1, oob_score=True)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",rnd_clf.oob_score_)\n",
    "rnd_clf_accuracy = (rnd_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',rnd_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For modeling purpose max_depth with right value is choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.8809833333333333\n",
      "Training accuracy =  0.9933\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=200, max_depth=20, n_jobs=-1, oob_score=True)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",rnd_clf.oob_score_)\n",
    "rnd_clf_accuracy = (rnd_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',rnd_clf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)Investigate the effect of the number of trees and the number of features used in the design of each tree on the performance of your classifier. Describe/document what you find.\n",
    "\n",
    "Ans:The OOB score is computed as the number of correctly predicted rows from the out of bag sample. So the score shows 59% of used data from the unusead data. Therefore we can say that only 59 Percent of features were used to design the performance of the model.From the results above we can say that as number of trees increases the OOB value increases. This means that when we increase the number of trees the selection of features is increasing respectively. \n",
    "###### At n_estimators = 100 we got oob as 59.60% and performance was 59.62%\n",
    "###### At n_estimators = 200 we got oob as 59.62% and performance was 59.62%\n",
    "###### At n_estimators = 300 we got oob as 60.28% and performance was 61.05%\n",
    "###### At n_estimators = 500 we got oob as 60.85% and performance  was 61.5%\n",
    "These results prove there will be an effect on performance of the model when trees and Features used in the design cahnges!\n",
    "\n",
    "#### Note: I choose hyper parameter max_depth= 2 for significant change in the values. The max_depth=15 is choosen in the end for model develpoment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(a)  Repeat parts (a) and (b) in the random forest exercise above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.8318666666666666\n",
      "Training accuracy =  0.8590666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#\n",
    "et_clf = ExtraTreesClassifier(n_estimators=100, max_depth=10,\n",
    "min_samples_split=2,bootstrap= True, n_jobs=-1,oob_score=True)\n",
    "et_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",et_clf.oob_score_)\n",
    "et_clf_accuracy = (et_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',et_clf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 5}\n",
      "0.8651166666666666\n"
     ]
    }
   ],
   "source": [
    "grid_param = { 'min_samples_leaf':[5, 10, 15, 20], 'max_depth':[5, 10, 15, 20], \n",
    "              'criterion': ['gini', 'entropy'] }\n",
    "gd_sr = GridSearchCV(estimator=et_clf, param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "gd_sr.fit(X_train, y_train)\n",
    "best_parameters = gd_sr.best _params_\n",
    "print(best_parameters)\n",
    "best_result = gd_sr.best_score_\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us adjust the max depth and min sample leaf and run the model with various estimators and see the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score when number of tree is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.56025\n",
      "Training accuracy =  0.5639666666666666\n"
     ]
    }
   ],
   "source": [
    "et_clf = ExtraTreesClassifier(n_estimators=100, max_depth=2,\n",
    "min_samples_split=2, min_samples_leaf= 5, bootstrap= True, n_jobs=-1,oob_score=True)\n",
    "et_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",et_clf.oob_score_)\n",
    "et_clf_accuracy = (et_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',et_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score when number of tree is 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.5827\n",
      "Training accuracy =  0.5860333333333333\n"
     ]
    }
   ],
   "source": [
    "et_clf = ExtraTreesClassifier(n_estimators=300, max_depth=2,\n",
    "min_samples_split=2, min_samples_leaf= 5, bootstrap= True, n_jobs=-1,oob_score=True)\n",
    "et_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",et_clf.oob_score_)\n",
    "et_clf_accuracy = (et_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',et_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values above are choosen for understanding the estimator importance. For calucucation purpose the we choose the estimator=200 and max depth=20, sampe leaf=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of Bag score 0.8662166666666666\n",
      "Training accuracy =  0.9369666666666666\n"
     ]
    }
   ],
   "source": [
    "et_clf = ExtraTreesClassifier(n_estimators=200, max_depth=20,\n",
    "min_samples_split=2, min_samples_leaf= 5, bootstrap= True, n_jobs=-1,oob_score=True)\n",
    "et_clf.fit(X_train, y_train)\n",
    "print(\"out of Bag score\",et_clf.oob_score_)\n",
    "et_clf_accuracy = (et_clf.predict(X_train) == y_train).mean()\n",
    "print('Training accuracy = ',et_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(b)Investigate the effect of the number of trees and the number of features used in the design of each tree on the performance of your classifier. Describe/document what you find.\n",
    "\n",
    "Ans:Similar to the above conclusion, we got the same results proving that  the performance of the model is effected by features and trees.\n",
    "\n",
    "hese results prove there will be an effect on performance of the model when trees and Features used in the design cahnges!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n",
    "Let us first find the best learning rate to handle our data.  We can explaint that our performance is getting better every time with a new classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.2,\n",
    "                                    max_depth=1, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gb_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on training set: 0.902"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Final Evaluation\n",
    "Based on the evaluation I believe that these models can be modeled in a much better way with proper tuning of hyper parameters but due to lack for my PC long time consuming performance made me restricted to these results.  The better analyser is gradient boosting with 89% accuracy with the above hyper parameters.\n",
    "###### Learning Rate must be inbetween 0.5 to 0.2 which is the best parameter for gradient boosting. The next best classifier is  random forest and extra tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on training set: 0.902\n",
    "\n",
    "Accuracy on training set: 0.898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.937\n",
      "Accuracy on test set: 0.869\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(et_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(et_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.993\n",
      "Accuracy on test set: 0.883\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rnd_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rnd_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.605\n",
      "Accuracy on test set: 0.603\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(ada_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(ada_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
